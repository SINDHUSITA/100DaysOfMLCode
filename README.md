# 100DaysOfMLCode
My journey towards expertise in Machine Learning. 
Day 1
I decided to start a dedicated learning journey from today.
I needed some motivation during the lockdown and that is when I came across the #100DaysOfMLCode challenge.
Committing to spend1-hour every day on machine learning for 100 days with all dedication and passion.

Day 1: Tried various techniques for feature scaling over a very small dataset. This is as a part of preprocessing for my Support Vector Regression model.
#100DaysOfMLCode 
#Regression #MachineLearining #FeatureScaling

Day 2: Implemented Decision Tree Regressor and Support Vector Regressor over a sample dataset. Also, I got an idea of how each of these works mathematically. 
It is really fun experimenting and checking out various outcomes.

Day 3: Feeling great as I completed the Part2, Regression, from the course that I am currently pursuing. A big thanks to the tutors 
@kirill_eremenko
 and @Hadelin_de_Ponteves who made the learning so simple and fun. Can't wait the begin the Part3, Classification.
 
 Day 3,4: For the first time, I took up a very common Regression Project (Boston House Price Prediction).
So far, I have built the model but, now working on improving the results.

#100DaysOfMLCode
#kaggle #regression

Please do find time to review my code here and I am open for any advice.
https://github.com/SINDHUSITA/100DaysOfMLCode/tree/master/Part%202%20-%20Regression/House%20Prices%20Project

Day 6,7: Brought my first project in Regression to a final shape and learned some evaluation metrics for Regression models. 
Very excited as I finally enrolled myself to "Machine Learning by Stanford University" course by 
@AndrewYNg
. 

#100DaysOfMLCode
#Coursera

Day 8: Yaay! I am now into week2 of #100DaysOfMLCode.
So far, I learned regression algorithms and analyzed them not only theoretically but also with mathematics, which I believe is one of the most interesting ways to learn ML.
Today, I worked on the basics of Logistic Regression.

Day 9,10: Implemented one of the classic classification algorithms, Logistic Regression, with Breast Cancer Wisconsin dataset from UCI.
Check it out here:
https://github.com/SINDHUSITA/Breast-Cancer-Prediction

Day 11,12: Analysed how the SVM classifier works. It is definitely one of the most complex yet, powerful algorithms one can come across. I had to read many articles to get the right gist of how a few of the kernel functions work. Links in the following thread.

Here are two good articles that will provide you with everything you need to know before implementing Support Vector Machine:

https://kdnuggets.com/2016/06/select-support-vector-machine-kernels.html

Day 13: For some reason, the Naive Bayes Classifier has always been my favorite algorithmFace with tongue.  Today, I revised it and tried implementing a different type of problem using it.
One good thing in Machine Learning is Mathematics and I am enjoying it.

Day 14: Implemented Decision Tree and Random Forest Classifier. It is the end of week 2 and also the end of 'Section: Classification' from my course!
Want to take up an interesting project based on Classification. Please share your suggestions.Smiling face with smiling eyes

Day 15,16: Everything was so perfect until a friend of mine suggested to consider uploading solutions in #kaggle and checking where my model stands. It actually turned out to be a terrible model. I have been working on the same.

Day 17-21: Worked on the famous 'Titanic survival prediction'. 
Also, I am going to call this week 3 as #kaggle week. The whole week, I kept trying so hard to improve my model and advance in the leaderboard.

Check out my Kaggle profile:
https://kaggle.com/sindhuinuganti
Day 22-25: Stepped into Unsupervised Learning and it is going great. 
Can't believe that it has been 25 days since I started this. 
Looking forward to continuing for the rest 3 quarters with the same enthusiasm.

Day 26-30: Taking baby steps into Deep Learning. There are numerous amazing resources available online just for free to help anyone get through this. I found #Coursera and #fasiai to be very useful and of course #YouTube too.

Day 31-36: Understanding how neural networks and deep learning work. Invested more time into theoretical concepts rather than practicing them. I am going to utilize this Week5 for practical knowledge and for getting comfortable with #TensorFlow.

Day 37,38: Learning Computer Vision Fundamentals with: Hand-Written Digit Recognizer from famous MNIST data.
Working on improving results for a #kaggle submission.
Also, explored how CNNs work.
My Kaggle: https://www.kaggle.com/sindhuinuganti

#100DaysOfMLCode
#DeepLearning #MachineLearning
